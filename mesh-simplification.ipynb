{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "RES_PATH = 'models' # Folder where all 3D models are kept. Same dir level as this file.\n",
    "\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print(f\"cannot find {RES_PATH} folder, please update RES_PATH\")\n",
    "    exit(1)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "import pyglet\n",
    "pyglet.options['shadow_window'] = False\n",
    "\n",
    "import pyrender\n",
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import heapq\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimesh Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh(filename):\n",
    "    mesh_fp = os.path.join(RES_PATH, filename)\n",
    "    \n",
    "    assert os.path.exists(mesh_fp), 'cannot found:'+mesh_fp\n",
    "    \n",
    "    t_mesh = trimesh.load(mesh_fp)\n",
    "    \n",
    "    return t_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh Simplification Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_valid_pairs(mesh, threshold):\n",
    "    thresh_squared = threshold ** 2\n",
    "    valid_pairs = []\n",
    "    edge_pair_map = dict() # Maps vertex indices to a set of all the vertex indices its paired to.\n",
    "    \n",
    "    # Updates the mapping of the pairs appropriately.\n",
    "    def update_mapping(v1, v2):\n",
    "        if v1 in edge_pair_map: edge_pair_map[v1].add(v2)\n",
    "        else: edge_pair_map[v1] = {v2}\n",
    "        \n",
    "        if v2 in edge_pair_map: edge_pair_map[v2].add(v1)\n",
    "        else: edge_pair_map[v2] = {v1}\n",
    "    \n",
    "    print(\"Getting edge pairs...\")\n",
    "    for edge in mesh.edges_unique:\n",
    "        valid_pairs.append([edge[0], edge[1]])\n",
    "        update_mapping(edge[0], edge[1])\n",
    "    \n",
    "    print(\"Getting vertex pairs within threshold...\")\n",
    "    # Gets vertex pairs within threshold.\n",
    "    for i, vert1 in enumerate(mesh.vertices):\n",
    "        j = i + 1\n",
    "        for vert2 in (mesh.vertices[j:]):\n",
    "            if not (i in edge_pair_map[j]): # Checks for duplicate pairs from the edges.\n",
    "                # Uses squared distance to avoid inefficient square root function.\n",
    "                sq_distance = np.sum((vert1-vert2) ** 2, axis=0)\n",
    "    \n",
    "                if sq_distance < thresh_squared: \n",
    "                    valid_pairs.append([i, j])\n",
    "                    update_mapping(i, j)\n",
    "        \n",
    "        print(f\"i = {i}/{len(mesh.vertices)-1}\")\n",
    "    \n",
    "    return valid_pairs\n",
    "\n",
    "def calculate_vertex_error_quadric(mesh, vertex_index):\n",
    "    tri_face_indices = mesh.vertex_faces[vertex_index]\n",
    "    \n",
    "    Q = np.zeros((4, 4))\n",
    "    for i in (i for i in tri_face_indices if i != -1): # Filters out padded -1s.\n",
    "        face = mesh.faces[i]\n",
    "        p1 = mesh.vertices[face[0]]\n",
    "        p2 = mesh.vertices[face[1]]\n",
    "        p3 = mesh.vertices[face[2]]\n",
    "        \n",
    "        # Calculates coefficients a, b, c and d, of the plane equation of the triangle face.\n",
    "        n = np.cross((p2 - p1), (p3 - p1))\n",
    "        a, b, c = n = n / np.linalg.norm(n)\n",
    "        d = np.dot(n, p1)\n",
    "        \n",
    "        K_p = np.array([[a**2, a*b, a*c, a*d],\n",
    "                        [a*b, b**2, b*c, b*d],\n",
    "                        [a*c, b*c, c**2, c*d],\n",
    "                        [a*d, b*d, c*d, d**2]])\n",
    "        Q += K_p\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_contraction(m, pair, q1, q2):\n",
    "    q_bar = q1 + q2\n",
    "    q_bar[3,:] = [0,0,0,1]\n",
    "    b = np.array([[0],[0],[0],[1]])\n",
    "    \n",
    "    if np.linalg.det(q_bar) != 0: result = -(np.linalg.inv(q_bar) @ b)\n",
    "    else: \n",
    "        result = (m.vertices[pair[0]] + m.vertices[pair[1]]) / 2\n",
    "        result = np.expand_dims(np.append(result, 1), axis=1)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(v_bar, pair, q1, q2):\n",
    "    error = v_bar.T@(q1 + q2)@v_bar\n",
    "    return error[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heap(m, pairs):\n",
    "    heap = []\n",
    "    for pair in pairs:\n",
    "        q1 = calculate_vertex_error_quadric(m, pair[0])\n",
    "        q2 = calculate_vertex_error_quadric(m, pair[1])\n",
    "        v_bar = compute_optimal_contraction(m, pair, q1, q2)\n",
    "        error = calculate_error(v_bar, pair, q1, q2)\n",
    "        heapq.heappush(heap, [error, pair])\n",
    "    return heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_error(mesh, pair):\n",
    "    q1 = calculate_vertex_error_quadric(mesh, pair[0])\n",
    "    q2 = calculate_vertex_error_quadric(mesh, pair[1])\n",
    "    new_v_bar = compute_optimal_contraction(mesh, pair, q1, q2)\n",
    "    error = calculate_error(new_v_bar, pair, q1, q2)\n",
    "    return error\n",
    "\n",
    "def update_valid_pairs(mesh, heap, v_bar_index, v1_index, v2_index):\n",
    "    # Find heap indices of where the pairs containing v1 and v2 are (since they will be changed\n",
    "    # when shifting the indices in the next loop).\n",
    "    heap_indices_to_update = []\n",
    "    \n",
    "    heap_indices_to_delete = [] # Prevents creating duplicate pairs with v_bar_index if v1_index and\n",
    "    vertices_paired = set()     # v2_index share a common index as a pair.\n",
    "    \n",
    "    for i, item in enumerate(heap):\n",
    "        pair = item[1]\n",
    "        \n",
    "        if pair[0] == v1_index or pair[0] == v2_index:\n",
    "            if pair[1] in vertices_paired: heap_indices_to_delete.append(i)\n",
    "            else:\n",
    "                heap_indices_to_update.append([i, 0])\n",
    "                vertices_paired.add(pair[1])\n",
    "        elif pair[1] == v1_index or pair[1] == v2_index:\n",
    "            if pair[0] in vertices_paired: heap_indices_to_delete.append(i)\n",
    "            else:\n",
    "                heap_indices_to_update.append([i, 1])\n",
    "                vertices_paired.add(pair[0])\n",
    "    \n",
    "    # Shifts vertex indices accordingly to accomodate for removed v1 and v2 vertices and added v_bar vertex.\n",
    "    for i, item in enumerate(heap):\n",
    "        pair = item[1]\n",
    "        shift1, shift2 = 0, 0\n",
    "        \n",
    "        if pair[0] > v1_index: shift1 -= 1\n",
    "        if pair[0] > v2_index: shift1 -= 1\n",
    "        if pair[1] > v1_index: shift2 -= 1\n",
    "        if pair[1] > v2_index: shift2 -= 1\n",
    "        \n",
    "        heap[i][1][0] += shift1\n",
    "        heap[i][1][1] += shift2\n",
    "        \n",
    "        if heap[i][1][0] >= v_bar_index: heap[i][1][0] += 1\n",
    "        if heap[i][1][1] >= v_bar_index: heap[i][1][1] += 1\n",
    "    \n",
    "    for index in sorted(heap_indices_to_delete, reverse=True):\n",
    "        heap.pop(index)\n",
    "        \n",
    "        # Shifts heap indices to accomodate for deletions.\n",
    "        for i, indices in enumerate(heap_indices_to_update):\n",
    "            if indices[0] > index: heap_indices_to_update[i][0] -= 1\n",
    "    \n",
    "    # Add v_bar_index to valid pairs and update error for its pairs.\n",
    "    for indices in heap_indices_to_update:\n",
    "        heap[indices[0]][1][indices[1]] = v_bar_index\n",
    "        pair = heap[indices[0]][1]\n",
    "        \n",
    "        heap[indices[0]][0] = calculate_new_error(mesh, pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_contract(mesh, v1_index, v2_index, v_bar):\n",
    "    i = v1_index if v1_index < v2_index else v2_index\n",
    "    mesh.vertices[v1_index] = mesh.vertices[v2_index] = v_bar\n",
    "    \n",
    "    # Uses this to get the index of the v_bar vertex after its merged.\n",
    "    unique, inverse = trimesh.grouping.unique_rows(mesh.vertices)\n",
    "    v_bar_index = np.where(unique == i)[0].item()\n",
    "    \n",
    "    mesh.merge_vertices()\n",
    "    mesh.remove_degenerate_faces()\n",
    "    \n",
    "    return v_bar_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_mesh(mesh, percent=0.8, threshold=0.7):\n",
    "    print(f\"Number of faces of original shape = {mesh.faces.shape[0]}\")\n",
    "    target_num_of_faces = int(mesh.faces.shape[0] * percent)\n",
    "    valid_pairs = get_all_valid_pairs(mesh, threshold)\n",
    "    print(\"Creating heap...\")\n",
    "    heap = create_heap(mesh, valid_pairs)\n",
    "\n",
    "    while len(heap) > 10 and target_num_of_faces < mesh.faces.shape[0]:\n",
    "        error, pair = heapq.heappop(heap)\n",
    "        v1_index, v2_index = pair[0], pair[1]\n",
    "        \n",
    "        q1 = calculate_vertex_error_quadric(mesh, pair[0])\n",
    "        q2 = calculate_vertex_error_quadric(mesh, pair[1])\n",
    "        v_bar = compute_optimal_contraction(mesh, pair, q1, q2)\n",
    "        v_bar = np.squeeze(v_bar[:3])\n",
    "        \n",
    "        v_bar_index = edge_contract(mesh, v1_index, v2_index, v_bar)\n",
    "        update_valid_pairs(mesh, heap, v_bar_index, v1_index, v2_index)\n",
    "        \n",
    "        print(f\"Heap size = {len(heap)}\")\n",
    "        \n",
    "    print(f\"Number of faces of simplified shape = {mesh.faces.shape[0]}\")\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m = load_mesh(\"armadillo.obj\")\n",
    "threshold = np.mean(m.edges_unique_length)\n",
    "print(f\"threshold = {threshold}\")\n",
    "print(f\"number of unique edges = {m.edges_unique.shape[0]}\")\n",
    "new_mesh = simplify_mesh(mesh=m, percent=0.7, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trimesh.exchange.export.export_mesh(new_mesh, \".\\\\new_armadillo.obj\", file_type=\"obj\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
